{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error as MAE, \n",
    "    mean_absolute_percentage_error as MAPE, \n",
    "    mean_squared_error as MSE) \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn import set_config\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data import load_data\n",
    "\n",
    "pd.set_option('display.precision',4)\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "plt.style.use('fivethirtyeight')\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the price of used cars\n",
    "In the data file [ToyotaCorrolla](../data/ToyotaCorolla.csv) we have data on used Toyotas from late 2004 in the Netherlands.  The goal is to predict the price based on it's specifications.\n",
    "\n",
    "Note there has been some significant EDA done ahead of time to reduce the number of columns and find interesting data.\n",
    "- Cylinders: dropped because all the values are 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Let's start by checking out the data\n",
    "cars_dtypes = {'Model':str,'Automatic':bool,'ABS':bool,'Airbag_1':bool,'Airbag_2':bool,'BOVAG_Guarantee':bool,\n",
    "    'Airco':bool,'Automatic_airco':bool,'Boardcomputer':bool,'CD_Player':bool,'Central_Lock':bool,\n",
    "    'Met_Color':bool,'Powered_Windows':bool,'Power_Steering':bool,'Radio':bool,'Mistlamps':bool,'Mfr_Guarantee':bool,'Sport_Model':bool,\n",
    "    'Backseat_Divider':bool,'Metallic_Rim':bool,'Radio_cassette':bool,'Parking_Assistant':bool,'Tow_Bar':bool}\n",
    "cars_df = load_data('ToyotaCorolla',dtype= cars_dtypes).drop(columns=['Cylinders'])\n",
    "cat_columns = ['Mfg_Month','Mfg_Year','Doors','Gears','Fuel_Type','Color']\n",
    "\n",
    "\n",
    "for c in cat_columns:\n",
    "    cars_df[c] = pd.Categorical(cars_df[c])\n",
    "\n",
    "# Take out the target column before determining the number columns\n",
    "num_columns = cars_df.drop(columns='Price').select_dtypes(include='number').columns\n",
    "bool_columns = cars_df.select_dtypes(include='bool').columns\n",
    "\n",
    "cars_df.head(5)\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df.columns\n",
    "cars_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq1,iq2,iq3 = cars_df.Price.describe()[4:7]\n",
    "sns.kdeplot(cars_df.Price, cumulative=True)\n",
    "y=np.full(len(cars_df.Price.cumsum()),0.5)\n",
    "plt.axhline(y=0.5,color='red',linestyle='--')\n",
    "plt.axhline(y=0.75,color='green',linestyle='--')\n",
    "plt.axhline(y=0.25,color='green',linestyle='--')\n",
    "plt.text(x=0.1*max(cars_df.Price),y=0.51,s=f'Median: {iq2}')\n",
    "plt.text(x=0.1*max(cars_df.Price),y=0.76,s=f'IQ3: {iq3}')\n",
    "plt.text(x=0.1*max(cars_df.Price),y=0.26,s=f'IQ1: {iq1}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cars_df.Price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df[bool_columns].apply(pd.value_counts).T\n",
    "cars_df[cat_columns].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=3, ncols=2,figsize=(20,25));\n",
    "for ax, c in zip(axs.flat,cat_columns):\n",
    "    sns.boxplot(data=cars_df, x=c,y='Price',ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see above that it looks like these values may have some interest (certainly the newer the car the more valuable)\n",
    "# There seems to be a small number of 2-doors let's see\n",
    "cars_df['Doors'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With only 2 samples of 2-door cars, we can safely drop these\n",
    "cars_df = cars_df.query('Doors>2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df.groupby('Color')['Price'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look through our booleans and see if they have any signficant outliers in terms of what yields higher price\n",
    "# We can do this with a simple t-Test\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "for c in bool_columns:\n",
    "    _, p_val = ttest_ind(cars_df[cars_df[c]==True].Price,cars_df[cars_df[c]==False].Price)\n",
    "    cars_df.groupby(c).Price.mean()\n",
    "    print(f'{c=} Mean Diff:{p_val<0.05}')\n",
    "# for c in bool_columns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cars_df.drop(columns='Price')\n",
    "y = cars_df['Price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are going to apply two transforms to our numeric columns\n",
    "# An imputer, to fill any gaps in our dataset with the median value\n",
    "# And a scaler which we can use to ensure our data is standardized\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "# For our categorical data, we'll use the OneHotEncoder\n",
    "#  In essense this will dummy the columns for us\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_columns),\n",
    "        (\"cat\", categorical_transformer, cat_columns)])\n",
    "\n",
    "kbest = SelectKBest(score_func=f_regression,k=8)\n",
    "column_transformer.fit_transform(X,y)\n",
    "# pipe = Pipeline([('col_trans',column_transformer),('kbest',kbest)])\n",
    "\n",
    "# pipe.fit_transform(X,y)\n",
    "# best_filter = kbest.get_support()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "set_config(display='diagram')\n",
    "\n",
    "# Reduce data frame to the top 1000 rows and select columns for regression analysis\n",
    "toyota_df = load_data('ToyotaCorolla',nrows=1000, \n",
    "            usecols=['Age_08_04', 'KM', 'Fuel_Type', 'HP', 'Met_Color', 'Automatic', 'CC', 'Doors', 'Quarterly_Tax', 'Weight', 'Price'])\n",
    "\n",
    "outcome = 'Price'\n",
    "\n",
    "num_columns = toyota_df.drop(columns=outcome).select_dtypes(include='number').columns\n",
    "cat_columns = toyota_df.select_dtypes(exclude=\"number\").columns\n",
    "\n",
    "# Here we are going to apply two transforms to our numeric columns\n",
    "# An imputer, to fill any gaps in our dataset with the median value\n",
    "# And a scaler which we can use to ensure our data is standardized\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "# For our categorical data, we'll use the OneHotEncoder\n",
    "#  In essense this will dummy the columns for us\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_columns),\n",
    "        (\"cat\", categorical_transformer, cat_columns)])\n",
    "\n",
    "toyota_reg = LinearRegression()\n",
    "\n",
    "# Here we define the transformers to use and which columns to apply them too\n",
    "pipeline = Pipeline([(\"col_transform\",column_transformer)\n",
    "            , (\"feature_selection\",SelectKBest())\n",
    "            , ('regression_model',toyota_reg)])\n",
    "pipeline"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
