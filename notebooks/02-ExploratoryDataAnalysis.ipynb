{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "Telling the future is the exciting part of data mining.  Everyone wants to build the best model that can be the most accurate prediction of future results or have the best explanation for why the past occurred the way it has.  But in order to have a valuable model, it is important to understand the data, determine the shape, understand the predictors and the target variables (if any).  Understanding the scale of these values and their relationship to each other can save hours of testing different modelling techniques and parameter tuning.\n",
    "\n",
    "The next cell is one that will appear in some configuration as the first in nearly every notebook.  It imports the key libraries we are going to use in our analysis and model building.  In the first case, we will depend on pandas and numpy for our data manipulation and we'll leverage matplotlib as our graphical library.  We'll also use the seaborn library to show off a few plots and visuals that are not quite as readily accessible with the matplotlib library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path('../data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston Housing Dataset\n",
    "Let's take a look at some basic data manipulation with pandas and understand how to get some data to work with.  In all of our examples, we'll use a pretty standard text format called (CSV) or comma-separated-values files.  This format is readable by nearly every statistical software package and by humans.  The first row is typically the name of the columns and each line of the file is a row of data with the values separated by commas.  The pandas library supports many different ways to load up a dataframe, which we will use as the primary mechanism for manipulating data in these notebooks.\n",
    "\n",
    "### Business Context\n",
    "Each record in the database describes a Boston suburb or town. The data was drawn from the Boston Standard Metropolitan Statistical Area (SMSA) in 1970. The attributes are deﬁned as follows (taken from the UCI Machine Learning Repository1):\n",
    "\n",
    "- **CRIM**: per capita crime rate by town\n",
    "- **ZN**: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- **INDUS**: proportion of non-retail business acres per town\n",
    "- **CHAS**: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- **NOX**: nitric oxides concentration (parts per 10 million)\n",
    "- **RM**: average number of rooms per dwelling\n",
    "- **AGE**: proportion of owner-occupied units built prior to 1940\n",
    "- **DIS**: weighted distances to ﬁve Boston employment centers\n",
    "- **RAD**: index of accessibility to radial highways\n",
    "- **TAX**: full-value property-tax rate per 10,000\n",
    "- **PTRATIO**: pupil-teacher ratio by town\n",
    "- **B**: 1000(Bk−0.63)2 where Bk is the proportion of blacks by town\n",
    "- **LSTAT**: % lower status of the population\n",
    "- **MEDV**: Median value of owner-occupied homes in 1000s\n",
    "- **CAT.MEDV**: Is median value of owner-occupied home in tract above $30k (CAT.MEDV = 1) or not (CAT.MEDV = 0)\n",
    "\n",
    "We can see that the input attributes have a mixture of units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the housing dataset\n",
    "housing_df = pd.read_csv(DATA_DIR/'BostonHousing.csv')\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column to be more convenient\n",
    "housing_df= housing_df.rename(columns={'CAT.MEDV':'CAT_MEDV'})\n",
    "# Take a look at the first few rows of data\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the rows and columns\n",
    "housing_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the ouput about that we have 506 rows and 14 columns, but we can't see all the columns - let's check out the column names and get an idea of the some descriptive statistics for each numerical column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an idea of the numerical fields.  We should check out the distribution of the CAT_MEDV field to see how these are laid out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.value_counts(['CAT_MEDV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take a look at a couple of values as they relate to our target variable (CAT_MEDV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.plot.scatter(x='LSTAT', y='MEDV', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=housing_df.groupby('CHAS').mean().MEDV.plot(kind='bar')\n",
    "ax.set_ylabel('Avg. MEDV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataForPlot= housing_df.groupby('CHAS').mean()['CAT_MEDV']*100\n",
    "ax=dataForPlot.plot(kind='bar', figsize=[5,3])\n",
    "ax.set_ylabel('% of CAT.MEDV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also be interested in the relationship between a set of the variables so that we can identify which ones may prove to be over-influencing a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing_df.corr())\n",
    "sns.heatmap(housing_df.corr(), cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationMatrix = housing_df.corr()\n",
    "# Convert our correlationMatrix to a one-dimensional array\n",
    "correlationMatrix = correlationMatrix.unstack()\n",
    "correlationMatrix[abs(correlationMatrix) > 0.7]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
