{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn import datasets\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data import load_data\n",
    "from src.metric import classificationSummary, confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "One of the most straightforward machine learning techniques is classification.  That is determining which category a to which particular observation belongs.  For example: \n",
    "* an individual passenger on the titanic was likely to survive,\n",
    "* which income bracket an individual is likely to be a part of \n",
    "* will a customer will qualify for a loan.\n",
    "\n",
    "All of these are classification questions.  Given a set of independent variables (e.g. factors) what is the likelihood that the dependent variable meets that category. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Predictive Performance\n",
    "Before we get too far into running algorithms we need a method to determine how good our model is.  There are a number of different metrics we might use.  But this depends on whether we are predicting/estimating a continuous target or a categorical target.  Some of the common methods are included here.\n",
    "\n",
    "Continuous Target\n",
    "* MAE - Mean absolute error\n",
    "* Mean Error - \n",
    "* MPE - Mean percentage error\n",
    "* MAPE - Mean absolute percentage error\n",
    "* RMSE - Root mean square error\n",
    "\n",
    "We will look at the continuous methods in depth in the [Estimation Notebook](04-EstimationPrediction.ipynb).\n",
    "\n",
    "Categorical Target\n",
    "- Misclassification Rate\n",
    "- Recall (aka True Positive Rate, hit rate, sensitivity)\n",
    "- Precision\n",
    "\n",
    "We'll focus here on _accuracy_ \n",
    "\n",
    "$$accuracy = \\frac{NumberOfCorrectPredictions}{AllPredictions}$$\n",
    "and _precision_\n",
    "$$precision = \\frac{TruePositives}{TruePositives+FalsePositives}$$\n",
    "\n",
    "### Naive Performance\n",
    "The simplest way to determine if a model is valuable or not is to compare to the \"naive rule\".  In essense, if we predict the most common outcome every time what is the misclassification rate.  If our model is no better than this, then our model isn't very helpful.\n",
    "\n",
    "For instance, let's say that in a list of 10 loan applicants that 8 of the applicants will be approved for a loan and that 2 won't be approved.  If we were to blindly assume that all 10 applicants would be approved for a loan - then we would be wrong 20% of the time (2/10).  Therefore, if we can't develop a model which is at least 80% accurate then we don't have a very good model.\n",
    "\n",
    "### Cut-off values for classification\n",
    "We also need to consider that in nearly all of our classification models, what we are given is the _probability_ or likelihood that the predicted target is in the given class, therefore the value we get from our classification algorithms is on a scale from 0 to 1.  Most often, the default is to say that a target belongs to a class if the probability of being in the class is > 0.5.  But it can be useful to move this cut-off.  For instance, if the cost of predicting a particular class is unusually high, we may want to raise the probability to 0.6 or greater."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using Logistic Regression\n",
    "Logistic regression, despite its name, is a linear model for classification rather than regression. Logistic regression is also known in the literature as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a [logistic function](https://en.wikipedia.org/wiki/Logistic_function).\n",
    "\n",
    "For this problem, we are going to jump right into the pattern we will use for running near all of our models.\n",
    "- Start by importing the data\n",
    "- Get a sense of the shape, type and features of the data\n",
    "- Perform any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>CARRIER</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>Weather</th>\n",
       "      <th>DAY_WEEK</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>Flight Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1455</td>\n",
       "      <td>OH</td>\n",
       "      <td>1455</td>\n",
       "      <td>JFK</td>\n",
       "      <td>184</td>\n",
       "      <td>01/01/2004</td>\n",
       "      <td>5935</td>\n",
       "      <td>BWI</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>N940CA</td>\n",
       "      <td>ontime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1640</td>\n",
       "      <td>DH</td>\n",
       "      <td>1640</td>\n",
       "      <td>JFK</td>\n",
       "      <td>213</td>\n",
       "      <td>01/01/2004</td>\n",
       "      <td>6155</td>\n",
       "      <td>DCA</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>N405FJ</td>\n",
       "      <td>ontime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245</td>\n",
       "      <td>DH</td>\n",
       "      <td>1245</td>\n",
       "      <td>LGA</td>\n",
       "      <td>229</td>\n",
       "      <td>01/01/2004</td>\n",
       "      <td>7208</td>\n",
       "      <td>IAD</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>N695BR</td>\n",
       "      <td>ontime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1715</td>\n",
       "      <td>DH</td>\n",
       "      <td>1709</td>\n",
       "      <td>LGA</td>\n",
       "      <td>229</td>\n",
       "      <td>01/01/2004</td>\n",
       "      <td>7215</td>\n",
       "      <td>IAD</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>N662BR</td>\n",
       "      <td>ontime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1039</td>\n",
       "      <td>DH</td>\n",
       "      <td>1035</td>\n",
       "      <td>LGA</td>\n",
       "      <td>229</td>\n",
       "      <td>01/01/2004</td>\n",
       "      <td>7792</td>\n",
       "      <td>IAD</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>N698BR</td>\n",
       "      <td>ontime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRS_DEP_TIME CARRIER  DEP_TIME DEST  DISTANCE     FL_DATE  FL_NUM ORIGIN  \\\n",
       "0          1455      OH      1455  JFK       184  01/01/2004    5935    BWI   \n",
       "1          1640      DH      1640  JFK       213  01/01/2004    6155    DCA   \n",
       "2          1245      DH      1245  LGA       229  01/01/2004    7208    IAD   \n",
       "3          1715      DH      1709  LGA       229  01/01/2004    7215    IAD   \n",
       "4          1039      DH      1035  LGA       229  01/01/2004    7792    IAD   \n",
       "\n",
       "   Weather  DAY_WEEK  DAY_OF_MONTH TAIL_NUM Flight Status  \n",
       "0        0         4             1   N940CA        ontime  \n",
       "1        0         4             1   N405FJ        ontime  \n",
       "2        0         4             1   N695BR        ontime  \n",
       "3        0         4             1   N662BR        ontime  \n",
       "4        0         4             1   N698BR        ontime  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start by importing a few key functions\n",
    "from sklearn.metrics import accuracy_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "delays_df = load_data('FlightDelays')\n",
    "delays_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: It maybe helpful here to get a sense of the dataset and decide how best to prepare it for modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.7955)\n",
      "\n",
      "       Prediction\n",
      "Actual   0   1\n",
      "     0 998  61\n",
      "     1 209  52\n"
     ]
    }
   ],
   "source": [
    "# convert to categorical\n",
    "delays_df.DAY_WEEK = delays_df.DAY_WEEK.astype('category')\n",
    "\n",
    "# create hourly bins departure time \n",
    "delays_df.CRS_DEP_TIME = [round(t / 100) for t in delays_df.CRS_DEP_TIME]\n",
    "delays_df.CRS_DEP_TIME = delays_df.CRS_DEP_TIME.astype('category')\n",
    "\n",
    "predictors = ['DAY_WEEK', 'CRS_DEP_TIME', 'ORIGIN', 'DEST', 'CARRIER']\n",
    "outcome = 'Flight Status'\n",
    "\n",
    "X = pd.get_dummies(delays_df[predictors])\n",
    "y = (delays_df[outcome] == 'delayed').astype(int)\n",
    "classes = ['ontime', 'delayed']\n",
    "\n",
    "# split into training and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.40, random_state=1)\n",
    "\n",
    "# run naive Bayes\n",
    "delays_nb = MultinomialNB(alpha=0.01)\n",
    "delays_nb.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "predProb_train = delays_nb.predict_proba(X_train)\n",
    "predProb_valid = delays_nb.predict_proba(X_valid)\n",
    "\n",
    "# predict class membership\n",
    "y_valid_pred = delays_nb.predict(X_valid)\n",
    "y_train_pred = delays_nb.predict(X_train)\n",
    "\n",
    "classificationSummary(y_train,y_train_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
