{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score, \n",
    "    KFold,\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    "    train_test_split, \n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from patsy.highlevel import dmatrices\n",
    "import pprint as pp\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data import load_data, load_excel, TRUE_VALUES, FALSE_VALUES\n",
    "from src.metric import confusion_matrix,classificationSummary\n",
    "\n",
    "pd.set_option('precision',4)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Techniques\n",
    "Python's power derives from it's collection of libraries and utilities which give complete control over the entire process of data mining.  In this notebook we'll explore a few."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the patsy library\n",
    "Developing interaction factors is a pretty common feature of many data science platforms and this can of course be done with Python as well.  The issue is that this requires a lot of `for` loops or recursive functions to develop all the interactions with the various variables. \n",
    "\n",
    "(from the [patsy documentation](https://patsy.readthedocs.io/en/latest/overview.html))\n",
    ">`patsy` is a Python package for describing statistical models (especially linear models, or models that have a linear component) and building design matrices. It is closely inspired by and compatible with the formula mini-language used in R and S.\n",
    ">\n",
    ">For instance, if we have some variable y, and we want to regress it against some other variables x, a, b, and the interaction of a and b, then we simply write:\n",
    ">\n",
    ">```patsy.dmatrices(\"y ~ x + a + b + a:b\", data)```\n",
    ">\n",
    "> and Patsy takes care of building appropriate matrices. Furthermore, it:\n",
    "> \n",
    "> * Allows data transformations to be specified using arbitrary Python code: instead of `x`, we could have written `log(x)`, `(x > 0)`, or even `log(x) if x > 1e-5 else log(1e-5)`,\n",
    "> * Provides a range of convenient options for coding categorical variables, including automatic detection and removal > of redundancies,\n",
    "> * Knows how to apply ‘the same’ transformation used on original data to new data, even for tricky transformations like > centering or standardization (critical if you want to use your model to make predictions),\n",
    "> * Has an incremental mode to handle data sets which are too large to fit into memory at one time,\n",
    "> * Provides a language for symbolic, human-readable specification of linear constraint matrices,\n",
    "> * Has a thorough test suite (>97% statement coverage) and solid underlying theory, allowing it to correctly handle > corner cases that even R gets wrong, and\n",
    "> * Features a simple API for integration into statistical packages.\n",
    "> \n",
    "> What Patsy won’t do is, well, statistics — it just lets you describe models in general terms. It doesn’t know or \n",
    "> care whether you ultimately want to do linear regression, time-series analysis, or fit a forest of decision trees,\n",
    ">  and it certainly won’t do any of those things for you — it just gives a high-level language for describing which \n",
    "> factors you want your underlying model to take into account. It’s not suitable for implementing arbitrary non-linear \n",
    "> models from scratch; for that, you’ll be better off with something like Theano, SymPy, or just plain Python. \n",
    "> But if you’re using a statistical package that requires you to provide a raw model matrix, then you can use Patsy to painlessly construct that model matrix; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and clean-up the heart disease dataset\n",
    "heart_df = load_excel('HeartDisease_Cleveland',\n",
    "                    dtype={'FBS': bool, 'EXANG': bool}, true_values=TRUE_VALUES,\n",
    "                    false_values=FALSE_VALUES, na_values=['?'])\n",
    "heart_df.dropna(inplace=True)\n",
    "heart_df['DIAG'] = (heart_df.NUM > 0)\n",
    "heart_df.drop(columns=['NUM'], inplace=True)\n",
    "# Set the MAX_NEIGHBORS\n",
    "MAX_NEIGHBORS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shape:(297, 19), y_shape:(297, 1)\n"
     ]
    }
   ],
   "source": [
    "# This function will build the matrices (that is the predictors with interactions)\n",
    "def setup_matricies(df):\n",
    "\n",
    "    # We'll look for DIAG as the target and \n",
    "    # Define SEX, CP, FBS, RESTECG, EXANG, SLOPE and THAL as categorical variables\n",
    "    # The other predictors are already seen as numeric\n",
    "    y, X = dmatrices('DIAG ~ AGE + C(SEX) + C(CP) + C(FBS) + TRESTBPS + CHOL +'\n",
    "                         'C(RESTECG) + THALACH + C(EXANG) + OLDPEAK + C(SLOPE) +'\n",
    "                         'CA + C(THAL) - 1', df, return_type='dataframe')\n",
    "\n",
    "    # The y (target) matrix uses dummy encoding for both True and False values, \n",
    "    #  since we only need to know if TRUE or not we can drop it\n",
    "    y.drop(columns=['DIAG[False]'],inplace=True)\n",
    "    y.rename(columns={'DIAG[True':'DIAG'}, inplace=True)\n",
    "\n",
    "    # For convenience we'll rename all the other columns so that we can read them\n",
    "    X.rename(columns={'C(SEX)[T.1]':'Male','C(CP)[T.2]':'CP_Atypical',\n",
    "                      'C(CP)[T.3]':'CP_NonAngina', 'C(CP)[T.4]':'CP_Asymptomatic',\n",
    "                      'C(FBS)[T.True]':'FBS_True', 'C(RESTECG)[T.1]':'RESTECG_1',\n",
    "                      'C(RESTECG)[T.2]':'RESTECG_2', 'C(EXANG)[T.1]':'EXANG_True',\n",
    "                      'C(SLOPE)[T.2]':'SLOPE_Flat', 'C(SLOPE)[T.3]':'SLOPE_Down',\n",
    "                      'C(THAL)[T.6.0]':'THAL_FIXED', 'C(THAL)[T.7.0]':'THAL_REV'},\n",
    "            inplace=True)\n",
    "\n",
    "    print(f'X_shape:{X.shape}, y_shape:{y.shape}')\n",
    "    y = np.ravel(y)\n",
    "    return X, y\n",
    "\n",
    "# It's convenient to have the preceding in a function so that we can call it again later if needed\n",
    "X, y = setup_matricies(heart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by setting the random_state variable, we can ensure that each time we run the method \n",
    "# we get the same splits\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.40, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best for K (simple) = 7 Score: 0.663866\n"
     ]
    }
   ],
   "source": [
    "# Now let's see if we can find a good model just by varying the values of K\n",
    "best_score = 0\n",
    "best_k = 0\n",
    "clf = None\n",
    "for K in range(1, MAX_NEIGHBORS, 2):\n",
    "    # We are only going to change the number of neighbors on each pass to see if it helps\n",
    "    clf = KNeighborsClassifier(n_neighbors=K, weights='uniform', algorithm='auto', n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    score = accuracy_score(y_valid, y_pred)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_k = K\n",
    "        best_y_pred = y_pred\n",
    "print(f'Best for K (simple) = {best_k} Score: {best_score:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation\n",
    "Another technique that helps us to ensure that we are not overfitting our model (that is we haven't learned so well on known data that it doesn't perform as well on unseen data.)  Typically we would split our dataset into training and validation (or test) sets.  This method uses a portion of our data to train the model and another hold-out portion to see how well the model fits some unseen data.  This can be helpful, but it still can lead to overfitting as we try to get a good model that performs well on the hold-out data.  One way to combat this approach is to use cross-validation.  While there are a number of approaches to cross-validation, the idea is the same:\n",
    "    \n",
    "1. Partition the data into a number of subsets\n",
    "2. Hold out 1 set at a time as our test set\n",
    "3. Train the model on the other sets\n",
    "4. Repeat the process for each subset\n",
    "\n",
    "We can cross-validate in a number of ways:\n",
    "* Leave one out cross validation\n",
    "* k-fold cross validation\n",
    "* Stratified k-fold cross validation\n",
    "* Time Series cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Fold Cross Validation\n",
    "<style>\n",
    ".center\n",
    "{\n",
    "    display:block;\n",
    "    margin-left: auto;\n",
    "    margin-right: auto;\n",
    "    width: 50%;\n",
    "}\n",
    "</style>\n",
    "Let's start with k-Fold Cross Validation\n",
    "\n",
    "The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation.\n",
    "If k=5 the dataset will be divided into 5 equal parts and the below process will run 5 times, each time with a different holdout set.\n",
    "1. Take the group as a holdout or test data set\n",
    "2. Take the remaining groups as a training data set\n",
    "3. Fit a model on the training set and evaluate it on the test set\n",
    "4. Retain the evaluation score and discard the model\n",
    "\n",
    "<img src='../img/k-fold-cv.png' width=400 height=400 class='center'/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best for K (cross_val) = 13 Score: 0.660113\n"
     ]
    }
   ],
   "source": [
    "# Here well do a simple k-Fold cross validation\n",
    "NUMBER_OF_SPLITS = 5\n",
    "best_c_val = 0\n",
    "best_k = 0\n",
    "best_model = None\n",
    "for n in range(1, MAX_NEIGHBORS, 2):\n",
    "    clf = KNeighborsClassifier(n_neighbors=n)\n",
    "    c_val = cross_val_score(clf, X, y, cv=NUMBER_OF_SPLITS, scoring='accuracy').mean()\n",
    "    if c_val > best_c_val:\n",
    "        best_c_val = c_val\n",
    "        best_k = n\n",
    "        best_model = clf\n",
    "print(f'Best for K (cross_val) = {best_k} Score: {best_c_val:.6f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified k-Fold Cross Validation\n",
    "This is the same concept as [k-Fold](#k-fold-cross-validation) but slightly different.  In this approach, rather than using a fixed size of for each set, the sets are broken up based on either a categorical predictor or categorical target (most often).  The idea is to ensure that each set has exactly the same proportion of the selected field in each set.\n",
    "<style>\n",
    ".center\n",
    "{\n",
    "    display:block;\n",
    "    margin-left: auto;\n",
    "    margin-right: auto;\n",
    "    width: 50%;\n",
    "}\n",
    "</style>\n",
    "<img src='../img/k-fold-strat.png' width=400 height=400 class='center'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CP</th>\n",
       "      <th>TRESTBPS</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>FBS</th>\n",
       "      <th>RESTECG</th>\n",
       "      <th>THALACH</th>\n",
       "      <th>EXANG</th>\n",
       "      <th>OLDPEAK</th>\n",
       "      <th>SLOPE</th>\n",
       "      <th>CA</th>\n",
       "      <th>THAL</th>\n",
       "      <th>DIAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  SEX  CP  TRESTBPS  CHOL    FBS  RESTECG  THALACH  EXANG  OLDPEAK  SLOPE   CA  THAL   DIAG\n",
       "0   63    1   1       145   233   True        2      150  False      2.3      3  0.0   6.0  False\n",
       "1   67    1   4       160   286  False        2      108   True      1.5      2  3.0   3.0   True\n",
       "2   67    1   4       120   229  False        2      129   True      2.6      2  2.0   7.0   True\n",
       "3   37    1   3       130   250  False        0      187  False      3.5      3  0.0   3.0  False\n",
       "4   41    0   2       130   204  False        2      172  False      1.4      1  0.0   3.0  False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.5387\n",
       "True     0.4613\n",
       "Name: DIAG, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start by looking at the breakdown of our classes\n",
    "ax = sns.barplot(x=['False','True'],y=np.array(heart_df.DIAG.value_counts()),)\n",
    "ax.bar_label(ax.containers[0])\n",
    "\n",
    "heart_df.DIAG.value_counts()/len(heart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best for K (stratified cross_val) = 13 Score: 0.660113\n"
     ]
    }
   ],
   "source": [
    "# Here we'll do a stratified k-Fold cross validation\n",
    "# Keep in mind this procedure works best when their are unbalanced classes in the target\n",
    "\n",
    "\n",
    "NUMBER_OF_SPLITS = 5\n",
    "best_c_val = 0\n",
    "best_k = 0\n",
    "best_model = None\n",
    "# The \n",
    "skf = StratifiedKFold(n_splits=NUMBER_OF_SPLITS)\n",
    "for train, test in skf.split(X,y):\n",
    "    for n in range(1, MAX_NEIGHBORS, 2):\n",
    "        clf = KNeighborsClassifier(n_neighbors=n)\n",
    "        c_val = cross_val_score(clf, X, y, cv=skf, scoring='accuracy').mean()\n",
    "        if c_val > best_c_val:\n",
    "            best_c_val = c_val\n",
    "            best_k = n\n",
    "            best_model = clf\n",
    "print(f'Best for K (stratified cross_val) = {best_k} Score: {best_c_val:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "Pipeline can be used to chain multiple estimators into one. This is useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification. Pipeline serves multiple purposes here:\n",
    "\n",
    "__Convenience and encapsulation__\n",
    "    <br/>You only have to call fit and predict once on your data to fit a whole sequence of estimators.\n",
    "\n",
    "__Joint parameter selection__\n",
    "    <br/>You can grid search over parameters of all estimators in the pipeline at once.\n",
    "\n",
    "__Safety__\n",
    "    <br/>Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.\n",
    "\n",
    "All estimators in a pipeline, except the last one, must be transformers (i.e. must have a transform method). The last estimator may be any type (transformer, classifier, etc.).\n",
    "\n",
    "*(source: [sklearn documentation](https://scikit-learn.org/stable/modules/compose.html#pipeline))*\n",
    "\n",
    "We can use a pipeline for instance to standardize our data prior to running the Nearest Neighbors classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('classifier',\n",
       "                 KNeighborsClassifier(n_jobs=-1, n_neighbors=23))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=K, weights='uniform', algorithm='auto', n_jobs=-1)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('classifier',clf)])\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7815126050420168"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now score our data\n",
    "pipe.score(X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best combination of parameters - GridSearch <a id='grid-search'></a>\n",
    "\n",
    "So far we have only dealt with a few parameters in our classifier and we used loops to try different values of `k` to determine the best number of neighbors for our model.  When we start to build up pipelines of estimators/classifiers/pre-processing which each have multiple parameters to tweak, if can be very difficult to keep track of combination of paramters that have been tried and which is the best.  The `sklearn` library has us covered.  In these cases we can use a [grid-search](https://scikit-learn.org/stable/modules/grid_search.html#grid-search).\n",
    "\n",
    "A grid-search is used to tune the 'hyper-parameters' (that is parameters that are not learnt with estimators).  In other words they are the parameters to the constructor for each classification/estimator function.  A grid search is a cross-validation method whereby different combinations of all the parameters are attempted.  [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) will try all the combinations exhaustively, while [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV) can sample the set of parameter combinations.  Both of these tools have successive halving counterparts which can be a bit quicker at finding the right combination.\n",
    "\n",
    "(Before blindly attempting to brute force try all the combinations of different parameters it is best to consult each estimator/transformer to see which parameters have the greatest impact.  sklearn provies a good [best practice](https://scikit-learn.org/stable/modules/grid_search.html#grid-search-tips)) guide which can help [avoid brute force parameter searches](https://scikit-learn.org/stable/modules/grid_search.html#alternative-cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_jobs=-1, n_neighbors=13)\n",
      "Best parameters for Grid Search: \n",
      "{'PCA__svd_solver': 'arpack',\n",
      " 'PCA__whiten': True,\n",
      " 'classifier__n_neighbors': 13,\n",
      " 'classifier__weights': 'uniform',\n",
      " 'feature_selection': SelectKBest()}\n",
      "Best score for Grid Search = 0.845172\n"
     ]
    }
   ],
   "source": [
    "# These are the parameters that will be used to try and come up with the best model\n",
    "param_grid = [\n",
    "    {\n",
    "        # Try a range of options to figure out the optimal number of features\n",
    "        # Accessing parameters of the pipeline by name takes the following form:\n",
    "        #  pipeline_step_name + '__' + parameter name\n",
    "        'classifier__n_neighbors': range(1,MAX_NEIGHBORS,2),\n",
    "        'classifier__weights': ['uniform', 'distance'],\n",
    "        'feature_selection' : [SelectKBest(f_classif)],\n",
    "        'PCA__whiten':[True, False],\n",
    "        'PCA__svd_solver':['auto', 'full', 'arpack', 'randomized'],\n",
    "    }\n",
    "]\n",
    "clf_pipe = Pipeline([('feature_selection', SelectKBest(f_classif)),\n",
    "                        ('PCA', PCA()),\n",
    "                    ('classifier', KNeighborsClassifier(n_jobs=-1))])\n",
    "\n",
    "# Go through an exhaustive search by combining all the variables specified in the\n",
    "clf = GridSearchCV(clf_pipe, cv=10, param_grid=param_grid, n_jobs=-1)\n",
    "# Again no need to have holdout data because the algorithm will hold out data for each k-fold pass\n",
    "clf.fit(X, y)\n",
    "# Now that we have fit the model, we'll take the best_estimator according to the GridSearch\n",
    "best_estimator = clf.best_estimator_.named_steps['classifier']\n",
    "print(f'{best_estimator}')\n",
    "print(f'Best parameters for Grid Search: ')\n",
    "pp.pprint(clf.best_params_)\n",
    "print(f'Best score for Grid Search = {clf.best_score_:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling\n",
    "Ensembling refers to learning in which multiple models are used to produce a single outcome.  Often these models are considered \"weak learners\" because they intentionally try to underfit so that the final model is not overfit when the models are combined.\n",
    "\n",
    "There are generally two different types of ensembling:\n",
    "*   __Averaging__ - in these approaches multiple models are created and the outcomes are aggregated into a final result.  The aggregation made be via voting or by averaging the responses.\n",
    "    *  _Examples include_: Bagging methods, and Randomized Trees\n",
    "*   __Boosting__ - alternatively boosting methods take weaker models and run them in series.  This means that the output of each model provides a factor for subsequent models to use in the learning task.  \n",
    "    *  _Examples include_: AdaBoost, Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHK_ACCT</th>\n",
       "      <th>DURATION</th>\n",
       "      <th>HISTORY</th>\n",
       "      <th>NEW_CAR</th>\n",
       "      <th>USED_CAR</th>\n",
       "      <th>FURNITURE</th>\n",
       "      <th>RADIO_TV</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>RETRAINING</th>\n",
       "      <th>AMOUNT</th>\n",
       "      <th>SAV_ACCT</th>\n",
       "      <th>EMPLOYMENT</th>\n",
       "      <th>INSTALL_RATE</th>\n",
       "      <th>MALE_DIV</th>\n",
       "      <th>MALE_SINGLE</th>\n",
       "      <th>MALE_MAR_or_WID</th>\n",
       "      <th>CO-APPLICANT</th>\n",
       "      <th>GUARANTOR</th>\n",
       "      <th>PRESENT_RESIDENT</th>\n",
       "      <th>REAL_ESTATE</th>\n",
       "      <th>PROP_UNKN_NONE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>OTHER_INSTALL</th>\n",
       "      <th>RENT</th>\n",
       "      <th>OWN_RES</th>\n",
       "      <th>NUM_CREDITS</th>\n",
       "      <th>JOB</th>\n",
       "      <th>NUM_DEPENDENTS</th>\n",
       "      <th>TELEPHONE</th>\n",
       "      <th>FOREIGN</th>\n",
       "      <th>RESPONSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBS#</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CHK_ACCT  DURATION HISTORY NEW_CAR USED_CAR FURNITURE RADIO_TV EDUCATION RETRAINING  AMOUNT SAV_ACCT EMPLOYMENT  INSTALL_RATE MALE_DIV MALE_SINGLE MALE_MAR_or_WID CO-APPLICANT GUARANTOR PRESENT_RESIDENT REAL_ESTATE PROP_UNKN_NONE   AGE OTHER_INSTALL RENT OWN_RES  NUM_CREDITS JOB  NUM_DEPENDENTS TELEPHONE FOREIGN RESPONSE\n",
       "OBS#                                                                                                                                                                                                                                                                                                                                   \n",
       "1           0       6.0       4       0        0         0        1         0          0  1169.0        4          4           4.0        0           1               0            0         0                4           1              0  67.0             0    0       1          2.0   2             1.0         1       0        1\n",
       "2           1      48.0       2       0        0         0        1         0          0  5951.0        0          2           2.0        0           0               0            0         0                2           1              0  22.0             0    0       1          1.0   2             1.0         0       0        0\n",
       "3           3      12.0       4       0        0         0        0         1          0  2096.0        0          3           2.0        0           1               0            0         0                3           1              0  49.0             0    0       1          1.0   1             2.0         0       0        1\n",
       "4           0      42.0       2       0        0         1        0         0          0  7882.0        0          3           2.0        0           1               0            0         1                4           0              0  45.0             0    0       0          1.0   2             2.0         0       0        1\n",
       "5           0      24.0       3       1        0         0        0         0          0  4870.0        0          2           3.0        0           1               0            0         0                4           0              1  53.0             0    0       0          2.0   2             2.0         0       0        0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# German Credit\n",
    "# Assume all columns are categorical\n",
    "credit_df = load_data('GermanCredit', index_col=\"OBS#\",dtype='category')\n",
    "credit_df.rename(columns={\"RADIO/TV\":\"RADIO_TV\",\"CO-APPLICANT\":\"CO-APPLICANT\"}, inplace=True)\n",
    "credit_df = credit_df.astype({'DURATION':float,'AMOUNT':float, 'INSTALL_RATE':float, 'AGE':float,'NUM_CREDITS':float,'NUM_DEPENDENTS':float})\n",
    "credit_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good for us we have a couple of ways to use Ensembling to make this work.  We can use the built in essemble methods like "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='center'/>\n",
    "\n",
    "[Back to TOC](./00-Introduction.ipynb)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
